{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"article_number\": \"Art. 1\",\n",
      "    \"title\": \"Allgemeines\",\n",
      "    \"text\": \"1\\nDieser Verordnung (Personalrecht) untersteht das Personal \\nder Stadt Z\\u00fcrich. \\n2\\nDie Verordnung ist nicht anwendbar auf Lehrpersonen der \\nVolksschule, die gem\\u00e4ss kantonalem Recht dem Lehrerpersonalgesetz unterstellt sind. \\n3\\nF\\u00fcr die \\u00fcbrigen st\\u00e4dtischen Lehrpersonen gelten diese Verordnung und ihre Ausf\\u00fchrungsbestimmungen, soweit nicht besondere Beschl\\u00fcsse des Gemeinderates etwas anderes \\nbestimmen oder auf kantonales Recht verweisen. \\n4\\nF\\u00fcr die Mitglieder des Stadtrates und der Vormundschaftsbeh\\u00f6rde, die Beauftragte oder den Beauftragten in Beschwerdesachen, die Datenschutzbeauftragte oder den Datenschutzbeauftragten, die Stadtamtsfrauen und Stadtamm\\u00e4nner, Friedensrichterinnen und Friedensrichter, Schulpr\\u00e4sidentinnen und \\nSchulpr\\u00e4sidenten gilt das Personalrecht sinngem\\u00e4ss, soweit \\nnicht besondere Bestimmungen bestehen. \",\n",
      "    \"metadata\": {\n",
      "        \"type\": \"Allgemeine Bestimmungen\",\n",
      "        \"tags\": [\n",
      "            \"Allgemeines\",\n",
      "            \"Verordnung\"\n",
      "        ],\n",
      "        \"created_at\": \"2024-05-21T11:00:00Z\"\n",
      "    }\n",
      "}\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to load JSON data from a file\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Function to save JSON data to a file\n",
    "def save_json(data, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Example usage\n",
    "file_path = 'articles.json'\n",
    "data = load_json(file_path)\n",
    "\n",
    "# Print first article to verify\n",
    "print(json.dumps(data[0], indent=4))\n",
    "print(len(data))\n",
    "\n",
    "\n",
    "# Save updated data\n",
    "save_json(data, file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD \"ABPR\" Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended attribute 'Gesetzestext' with value 'PR' to the 'metadata' in all entries of the JSON file.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def append_attribute_to_all_entries(file_path, new_attribute_name, new_attribute_value):\n",
    "    # Read the existing JSON data from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    \n",
    "    # Check if json_data is a list\n",
    "    if isinstance(json_data, list):\n",
    "        for entry in json_data:\n",
    "            # Check if 'metadata' exists and is a dictionary in each entry\n",
    "            if 'metadata' in entry and isinstance(entry['metadata'], dict):\n",
    "                # Append the new attribute to the 'metadata' dictionary\n",
    "                entry['metadata'][new_attribute_name] = new_attribute_value\n",
    "            else:\n",
    "                print(f\"Error: 'metadata' key not found or is not a dictionary in entry {entry}.\")\n",
    "                return\n",
    "    else:\n",
    "        print(\"Error: JSON data is not a list of entries.\")\n",
    "        return\n",
    "    \n",
    "    # Write the updated JSON data back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(json_data, file, indent=4)\n",
    "    \n",
    "    print(f\"Appended attribute '{new_attribute_name}' with value '{new_attribute_value}' to the 'metadata' in all entries of the JSON file.\")\n",
    "\n",
    "# Example usage\n",
    "file_path = 'PR.json'  # Path to your JSON file\n",
    "new_attribute_name = 'Gesetzestext'\n",
    "new_attribute_value = 'PR'\n",
    "\n",
    "append_attribute_to_all_entries(file_path, new_attribute_name, new_attribute_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load data from a file\n",
    "with open('articles.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Remove the \"embedding\" part\n",
    "for article in data:\n",
    "    if 'embedding' in article:\n",
    "        del article['embedding']\n",
    "\n",
    "# Save the modified data back to the file\n",
    "with open('articles_new', 'w', encoding='utf-8') as file:\n",
    "    json.dump(data, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article_number': 'Art. 37', 'title': 'Anhörung vor personalrechtlichen Anordnungen', 'text': '\\n\\nDie Angestellten sind vor Erlass einer sie belastenden Verfü-\\ngung anzuhören. \\n2\\nVon der vorgängigen Anhörung kann abgesehen werden, \\nwenn ein sofortiger Entscheid im öffentlichen Interesse notwen\\ufffedig ist. Die Anhörung ist so bald wie möglich nachzuholen, spä-\\ntestens innert 30 Tagen. \\n3\\nDie Angestellten können eine Person ihres Vertrauens beizie\\ufffehen. \\n\\n', 'metadata': {'type': 'Rechtsschutz', 'tags': ['Zumutbarkeit', 'Versetzung', 'Anhörung', 'personalrechtlichen', 'Anordnungen'], 'created_at': '2024-05-21T11:00:00Z'}}\n"
     ]
    }
   ],
   "source": [
    "# Function to add a new article\n",
    "def add_article(data, article_number, title, text, metadata):\n",
    "    new_article = {\n",
    "        \"article_number\": article_number,\n",
    "        \"title\": title,\n",
    "        \"text\": text,\n",
    "        \"metadata\": metadata\n",
    "    }\n",
    "    data.append(new_article)\n",
    "    return data\n",
    "\n",
    "# Adding a new article\n",
    "new_article_metadata = {\n",
    "    \"type\": \"Rechtsschutz\",\n",
    "    \"tags\": [\"Zumutbarkeit\",\"Versetzung\", \"Anhörung\", \"personalrechtlichen\", \"Anordnungen\"],\n",
    "    \"created_at\": \"2024-05-21T11:00:00Z\"\n",
    "}\n",
    "data = add_article(data, \"Art. 37\", \"Anhörung vor personalrechtlichen Anordnungen\", \"\"\"\n",
    "\n",
    "Die Angestellten sind vor Erlass einer sie belastenden Verfü-\n",
    "gung anzuhören. \n",
    "2\n",
    "Von der vorgängigen Anhörung kann abgesehen werden, \n",
    "wenn ein sofortiger Entscheid im öffentlichen Interesse notwen￾dig ist. Die Anhörung ist so bald wie möglich nachzuholen, spä-\n",
    "testens innert 30 Tagen. \n",
    "3\n",
    "Die Angestellten können eine Person ihres Vertrauens beizie￾hen. \n",
    "\n",
    "\"\"\", new_article_metadata)\n",
    "\n",
    "# Save updated data\n",
    "save_json(data, file_path)\n",
    "print (data[len(data)-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article_number': 'Art. 26', 'title': 'Spezialfälle', 'text': '\\n                   \\nDer Stadtrat kann spezielle Regelungen über den Altersrücktritt \\nund die Beendigung des Arbeitsverhältnisses altershalber für \\nAngestellte mit Lebensarbeitszeitmodellen oder für bestimmte \\nBerufs- und Funktionsbereiche erlassen.    \\n\\n', 'metadata': {'type': 'Beendigung', 'tags': ['Beendigungsgründe', 'Arbeitsverhältnisse', 'Kündigung', 'BeendigungSpezialfälle'], 'created_at': '2024-05-21T11:00:00Z'}}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Vectore Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to load JSON data from a file\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Example usage\n",
    "file_path = 'articles_incl_ARG.json'\n",
    "data = load_json(file_path)\n",
    "\n",
    "print(len(data))\n",
    "# Print first article to verify\n",
    "#print(json.dumps(data[0], indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "# Set your OpenAI API key\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key \n",
    "# Function to generate embeddings using the OpenAI API\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "import openai\n",
    "\n",
    "def get_embedding(text, tags, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    combine = text + \" \" .join(tags)\n",
    "    return openai.embeddings.create(input=[combine], model=model).data[0].embedding\n",
    "\n",
    "# Function to load JSON data from a file\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Function to save JSON data to a file\n",
    "def save_json(data, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "file_path = 'ARG.json'\n",
    "data = load_json(file_path)\n",
    "file_path_new = 'ARG_embedded.json'\n",
    "\n",
    "# Assuming you have your data loaded and structured\n",
    "for article in data:\n",
    "    article_text = article['text']\n",
    "    article_tags = article['metadata']['tags']\n",
    "    article['embedding'] = get_embedding(article_text, article_tags)\n",
    "\n",
    "# Save the updated data with embeddings back to the JSON file\n",
    "save_json(data, file_path_new)\n",
    "\n",
    "# Extract embeddings from the articles\n",
    "embeddings = np.array([article['embedding'] for article in data]).astype('float32')\n",
    "\n",
    "# Create a base index - L2 distance\n",
    "base_index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "\n",
    "# Create an IndexIDMap\n",
    "index = faiss.IndexIDMap(base_index)\n",
    "\n",
    "# IDs for the articles\n",
    "ids = np.array([i for i in range(len(data))], dtype='int64')  # Ensure IDs are int64\n",
    "\n",
    "# Add vectors and their IDs to the index\n",
    "index.add_with_ids(embeddings, ids)\n",
    "\n",
    "# Save the index to disk\n",
    "faiss.write_index(index, \"arg.index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Extract embeddings from the articles\n",
    "embeddings = np.array([article['embedding'] for article in data]).astype('float32')\n",
    "\n",
    "# Create a base index - L2 distance\n",
    "base_index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "\n",
    "# Create an IndexIDMap\n",
    "index = faiss.IndexIDMap(base_index)\n",
    "\n",
    "# IDs for the articles\n",
    "ids = np.array([i for i in range(len(data))], dtype='int64')  # Ensure IDs are int64\n",
    "\n",
    "# Add vectors and their IDs to the index\n",
    "index.add_with_ids(embeddings, ids)\n",
    "\n",
    "# Save the index to disk\n",
    "faiss.write_index(index, \"articles.index\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Erhalte ich bezahlten Urlaub für meinen Einsatz für Jugend und Sport? \"\n",
    "filter = \"Gesetzestext\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter nach \"Gesetzestext type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered entries have been written to filtered_articles.json.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def filter_entries(input_file_path, output_file_path, attribute_name, attribute_value):\n",
    "    # Read the existing JSON data from the input file\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    \n",
    "    # Initialize a list to hold the filtered entries\n",
    "    filtered_entries = []\n",
    "\n",
    "    # Check if json_data is a list\n",
    "    if isinstance(json_data, list):\n",
    "        for entry in json_data:\n",
    "            # Check if 'metadata' exists and is a dictionary in each entry\n",
    "            if 'metadata' in entry and isinstance(entry['metadata'], dict):\n",
    "                # Add to filtered list if the attribute matches the filter value\n",
    "                if entry['metadata'].get(attribute_name) == attribute_value:\n",
    "                    filtered_entries.append(entry)\n",
    "            else:\n",
    "                print(f\"Error: 'metadata' key not found or is not a dictionary in entry {entry}.\")\n",
    "    else:\n",
    "        print(\"Error: JSON data is not a list of entries.\")\n",
    "    \n",
    "    # Write the filtered entries to the output file\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        json.dump(filtered_entries, file, indent=4)\n",
    "    \n",
    "    print(f\"Filtered entries have been written to {output_file_path}.\")\n",
    "\n",
    "# Example usage\n",
    "input_file_path = 'articles_incl_ARG_embedded.json'  # Path to your input JSON file\n",
    "output_file_path = 'filtered_articles.json'  # Path to your output JSON file\n",
    "attribute_name = filter\n",
    "attribute_value = 'ARG'\n",
    "\n",
    "filter_entries(input_file_path, output_file_path, attribute_name, attribute_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# Set your OpenAI API key\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "def refine_query(query):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": f\"You are a helpful assistant. You Refine the searchquerry from the user: '{user_query}', so it yield the best results when used for a RAG request. Expand the Question to cover possible directly related topics that are relevant to get the best answer\"},\n",
    "    ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Erhalte ich bezahlten Urlaub für meinen Einsatz für Jugend und Sport? Welche Arbeitsrechte gelten für Freiwillige im Bereich Jugend und Sport? Gibt es gesetzliche Regelungen zum Urlaubsanspruch für ehrenamtliche Tätigkeiten im Sportbereich?\"\n"
     ]
    }
   ],
   "source": [
    "refind_query = refine_query(user_query)\n",
    "print(refind_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Perform the search\u001b[39;00m\n\u001b[0;32m     17\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# Number of nearest neighbors to retrieve\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m distances, indices \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Retrieve the matching articles\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Assuming article IDs were stored as sequential integers:\u001b[39;00m\n\u001b[0;32m     22\u001b[0m matching_articles \u001b[38;5;241m=\u001b[39m [data[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices[\u001b[38;5;241m0\u001b[39m]]  \u001b[38;5;66;03m# Direct access by index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\spunk\\anaconda3\\envs\\ChatTest\\Lib\\site-packages\\faiss\\class_wrappers.py:329\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_search\u001b[1;34m(self, x, k, params, D, I)\u001b[0m\n\u001b[0;32m    327\u001b[0m n, d \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    328\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(x, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 329\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m k \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m D \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import openai\n",
    "\n",
    "# Function to generate query embeddings using OpenAI API\n",
    "def generate_query_embedding(query,):\n",
    "    return get_embedding(query, [])\n",
    "\n",
    "# Example user query\n",
    "def get_response_string():\n",
    "    query_embedding = np.array(generate_query_embedding(refind_query)).astype('float32').reshape(1, -1)\n",
    "\n",
    "    # Load the index from disk\n",
    "    index = faiss.read_index(\"articles_ARG.index\")\n",
    "\n",
    "    # Perform the search\n",
    "    k = 5  # Number of nearest neighbors to retrieve\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "    # Retrieve the matching articles\n",
    "    # Assuming article IDs were stored as sequential integers:\n",
    "    matching_articles = [data[i] for i in indices[0]]  # Direct access by index\n",
    "    response_string = \"\"\n",
    "    # Print the matching articles\n",
    "    for article in matching_articles:\n",
    "        #print(matching_articles)\n",
    "        #print(f\"\\n Article Number: {article['article_number']}, \\n Title: {article['title']}, \\n Type:  {article['metadata']['type']} \\n Text: {article['text']}\")\n",
    "        response_string += f\"Article Number: {article['article_number']}, Title: {article['title']},Gesetzestext: {article['metadata']['Gesetzestext']},\\n Text: {article['text']}\" + \"\\n\"\n",
    "    print(len(response_string))\n",
    "    print(response_string)\n",
    "    return response_string\n",
    "\n",
    "response_string = get_response_string()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ja, als Angestellter des Stadtspitals Zürich kannst du bezahlten Urlaub für deinen Einsatz im Bereich Jugend und Sport erhalten. Gemäß Art. 132 des Gesetzestextes \"Verschiedene weitere Gründe für bezahlten Urlaub\" wird bezahlter Urlaub gewährt:\n",
      "\n",
      "- \"für ausserschulische Jugendarbeit, einschliesslich Leitung von Jugend- und Sportprogrammen: höchstens 10 Arbeitstage pro Jahr\"\n",
      "- \"für die Teilnahme an Jugend- und Sportprogrammen: höchstens 5 Arbeitstage pro Kalenderjahr\"\n",
      "\n",
      "Es ist jedoch zu beachten, dass \"allfällige Erwerbsausfallentschädigungen des Bundes an die Stadt abzuliefern sind.\"\n",
      "\n",
      "Bezüglich spezifischer Programme oder Organisationen, die finanzielle Unterstützung für Freiwillige bieten, kann ich auf Basis der gegebenen Informationen keine detaillierten Angaben machen. Es wird jedoch empfohlen, bei relevanten Regierungsstellen oder spezifischen Organisationen nachzufragen, die möglicherweise zusätzliche Unterstützung anbieten könnten.\n",
      "\n",
      "**Relevante Artikel und Artikeltitel:**\n",
      "- Article Number: Art. 132, Title: Verschiedene weitere Gründe für bezahlten Urlaub\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client = openai.OpenAI()\n",
    "from dotenv import load_dotenv\n",
    "# Set your OpenAI API key\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "system_query = f\"\"\"Du bist ein Assistent, welcher Fragen von Angestellten des Stadtspitals Zürich beantwortet. Antworte NUR basierend auf den Inhalten in den folgenden Artikeln: '{response_string}'.\n",
    "Wenn ja, antworte professionell. Verwende direkte Zitate aus den Artikeln und setze diese in Anführungszeichen. Gib am Ende eine Liste aller relevanten Artikel und Artikeltitel an. \"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  #model=\"gpt-3.5-turbo-0125\",\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": f\"{system_query}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{refind_query}\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print()\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChatTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
